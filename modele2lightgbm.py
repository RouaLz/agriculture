# -*- coding: utf-8 -*-
"""Modele2LightGBM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZaTRV-dipOEGxyv9L3C7kM7mkKlsZsnK
"""

# MODÈLE 2 : LightGBM
!pip install lightgbm -q

import pandas as pd
import numpy as np
from google.colab import files
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import lightgbm as lgb
import time

start_time = time.time()

# 1. Upload
print("Téléchargez crop_yield.csv")
uploaded = files.upload()
csv_path = list(uploaded.keys())[0]

# 2. Chargement et exploration des données
df = pd.read_csv(csv_path)
print(f"Données : {df.shape[0]} lignes, {df.shape[1]} colonnes")

print("=== NOMS EXACTS DES COLONNES ===")
for i, col in enumerate(df.columns):
    print(f"{i+1:2d}. '{col}' → longueur: {len(col)}, repr: {repr(col)}")

# → Affiche les noms exacts des colonnes (très utile quand il y a des espaces invisibles).

# 3. Détection label
label_col = next((c for c in df.columns if any(x in c.lower() for x in ['label', 'class', 'target', 'disease'])), None)
if not label_col:
    label_col = input("Nom de la colonne cible : ")

# 4. Nettoyage
df = df.dropna(subset=[label_col])
feature_cols = [c for c in df.columns if c != label_col]

# Encodage
le = LabelEncoder()
y = le.fit_transform(df[label_col])
X = df[feature_cols].copy()

# LightGBM gère les NaN et catégorielles
for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = X[col].astype('category')

# 5. Split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# 6. Modèle LightGBM
train_data = lgb.Dataset(X_train, label=y_train)
val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

# 6. Paramètres
params = {
    'objective': 'multiclass', # Problème de classification multi-classes
    'num_class': len(le.classes_), # Nombre total de classes uniques dans la colonne cible
    'metric': 'multi_logloss', # La métrique d'évaluation est la perte logarithmique multi-classes
    'learning_rate': 0.1, # Taux d'apprentissage, contrôle la taille des pas dans l'optimisation
    'num_leaves': 31, # Nombre maximal de feuilles dans un arbre de décision
    'feature_fraction': 0.8, # Fraction des features sélectionnées aléatoirement pour chaque arbre (pour éviter l'overfitting)
    'bagging_fraction': 0.8, # Fraction des données (échantillons) sélectionnées aléatoirement pour chaque itération (bagging)
    'bagging_freq': 5, # Fréquence du bagging (toutes les 5 itérations)
    'verbosity': -1 # Supprime les messages d'itération pendant l'entraînement
}

# 7. CALLBACK pour early stopping
early_stop = lgb.early_stopping(stopping_rounds=10, verbose=False)

print("Entraînement LightGBM...")
model = lgb.train(
    params,
    train_data,
    num_boost_round=100,
    valid_sets=[train_data, val_data],
    valid_names=['train', 'valid'],
    callbacks=[early_stop]  # ← ICI LE CALLBACK
)
# --> Évite le sur-apprentissage + choisit le meilleur moment

# 7. Prédiction
# Fait des prédictions de probabilités de classe sur l'ensemble de validation
y_pred = np.argmax(model.predict(X_val), axis=1) # -> récupère l'indice (la classe prédite) avec la plus haute probabilité
acc = accuracy_score(y_val, y_pred)  # Calcule l'accuracy (précision globale)


print(f"\nLightGBM - Accuracy : {acc:.4f}")
print("Classification Report :")
print(classification_report(y_val, y_pred, target_names=le.classes_))

print(f"\nTemps total : {time.time() - start_time:.1f} secondes")

#Les Résultats :
#Accuracy : 0.1659 (~17%) → Cela signifie que le modèle ne prédit correctement la culture que dans environ 1 cas sur 6.
#Precision : parmi les prédictions faites pour une classe, quelle proportion est correcte.
#Recall : parmi les vrais exemples d’une classe, quelle proportion a été correctement retrouvée.
#F1-score : moyenne harmonique de précision et rappel (équilibre entre les deux).
#Support : nombre d’exemples de cette classe dans l’ensemble de validation.

# ================================
# GRAPHE : Matrice de confusion + Importance des features
# ================================

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np

# 1. Prédictions sur validation
y_pred_proba = model.predict(X_val)
y_pred = y_pred_proba.argmax(axis=1)

# 2. Matrice de confusion
cm = confusion_matrix(y_val, y_pred)
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Matrice de Confusion')
plt.xlabel('Prédit')
plt.ylabel('Vrai')
plt.xticks(rotation=45)
plt.yticks(rotation=0)

# 3. Importance des features
plt.subplot(1, 2, 2)
importances = model.feature_importance(importance_type='gain')
feature_names = X.columns
indices = np.argsort(importances)[::-1]

plt.bar(range(len(importances)), importances[indices], color='skyblue')
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right')
plt.title('Importance des Features (Gain)')
plt.ylabel('Gain')
plt.tight_layout()
plt.show()

# 4. Rapport détaillé
print("\n" + "="*60)
print("           RAPPORT DE CLASSIFICATION")
print("="*60)
print(classification_report(y_val, y_pred, target_names=le.classes_))
print("="*60)